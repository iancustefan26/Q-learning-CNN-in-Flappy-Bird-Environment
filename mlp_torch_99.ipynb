{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets # for Mist\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn # To inherit our neural network\n",
    "from torch.utils.data import DataLoader # For management of the dataset (batches)\n",
    "from tqdm import tqdm # For nice progress bar!\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flappy_bird_gymnasium\n",
    "import gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2cf5d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = torch.device(device)\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d13b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "data_type = torch.float32\n",
    "input_size = 784\n",
    "epochs = 15\n",
    "batch_size = 64\n",
    "learning_rate = 0.0012\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28a89930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(10),     # Rotate +/- 10 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), # Shift image by 10%\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Apply these transforms ONLY to the training set\n",
    "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=train_transforms, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b500a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf84b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = nn.Sequential(\n",
    "    nn.Flatten(), # Ensures input is flattened automatically\n",
    "    \n",
    "    # Layer 1: Wide expansion\n",
    "    nn.Linear(784, 512), \n",
    "    nn.BatchNorm1d(512), # normalization keeps values stable\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),     # prevents memorization\n",
    "    \n",
    "    # Layer 2: Maintaining width\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    \n",
    "    # Layer 3: Output\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "layers.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa2e6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "920ed8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(params= model.parameters(), lr = learning_rate, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3cc6ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Data type: torch.float32\n",
      "Input size: 784\n",
      "Epochs: 15\n",
      "Batch size: 64\n",
      "Learning rate: 0.0012\n",
      "Number of classes: 10\n",
      "Device: mps\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.0012\n",
      "    lr: 0.0012\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.0601, -0.0344, -0.0022,  ...,  0.0513, -0.0210,  0.0175],\n",
      "        [ 0.0623,  0.0306,  0.0600,  ...,  0.0111, -0.0049, -0.0577],\n",
      "        [-0.0260, -0.0356, -0.0430,  ...,  0.0546, -0.0492,  0.0132],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0103,  0.0522,  ...,  0.0565, -0.0137, -0.0397],\n",
      "        [-0.0059, -0.0059, -0.0493,  ...,  0.0142, -0.0337,  0.0076],\n",
      "        [ 0.0342,  0.0612,  0.0656,  ..., -0.0084, -0.0370, -0.0286]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Print hyperparameters\n",
    "print(f\"Data type: {data_type}\")\n",
    "print(f\"Input size: {input_size}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Loss function: {loss_function}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "print(next(model.parameters()))\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            predictions = softmax(scores).argmax(dim=1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} correct ({float(num_correct)/float(num_samples)*100:.2f}%)\")\n",
    "    \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 117.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.3676938540788729\n",
      "Accuracy on training set:\n",
      "Got 56480 / 60000 correct (94.13%)\n",
      "Accuracy on test set:\n",
      "Got 9688 / 10000 correct (96.88%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 117.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Loss: 0.19472320911202476\n",
      "Accuracy on training set:\n",
      "Got 57388 / 60000 correct (95.65%)\n",
      "Accuracy on test set:\n",
      "Got 9736 / 10000 correct (97.36%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 108.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Loss: 0.16088385077546846\n",
      "Accuracy on training set:\n",
      "Got 57669 / 60000 correct (96.11%)\n",
      "Accuracy on test set:\n",
      "Got 9775 / 10000 correct (97.75%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 110.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Loss: 0.1397021505802965\n",
      "Accuracy on training set:\n",
      "Got 57967 / 60000 correct (96.61%)\n",
      "Accuracy on test set:\n",
      "Got 9815 / 10000 correct (98.15%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 112.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Loss: 0.1270073192722317\n",
      "Accuracy on training set:\n",
      "Got 57999 / 60000 correct (96.67%)\n",
      "Accuracy on test set:\n",
      "Got 9818 / 10000 correct (98.18%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:07<00:00, 123.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Loss: 0.11531567542370894\n",
      "Accuracy on training set:\n",
      "Got 58131 / 60000 correct (96.89%)\n",
      "Accuracy on test set:\n",
      "Got 9843 / 10000 correct (98.43%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 111.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Loss: 0.1057416654076737\n",
      "Accuracy on training set:\n",
      "Got 58516 / 60000 correct (97.53%)\n",
      "Accuracy on test set:\n",
      "Got 9861 / 10000 correct (98.61%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 98.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Loss: 0.09413813754294648\n",
      "Accuracy on training set:\n",
      "Got 58625 / 60000 correct (97.71%)\n",
      "Accuracy on test set:\n",
      "Got 9841 / 10000 correct (98.41%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 109.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Loss: 0.08455694809522249\n",
      "Accuracy on training set:\n",
      "Got 58809 / 60000 correct (98.02%)\n",
      "Accuracy on test set:\n",
      "Got 9886 / 10000 correct (98.86%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 106.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Loss: 0.07755342794598134\n",
      "Accuracy on training set:\n",
      "Got 58953 / 60000 correct (98.26%)\n",
      "Accuracy on test set:\n",
      "Got 9889 / 10000 correct (98.89%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 106.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Loss: 0.06942413114398512\n",
      "Accuracy on training set:\n",
      "Got 59029 / 60000 correct (98.38%)\n",
      "Accuracy on test set:\n",
      "Got 9896 / 10000 correct (98.96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 102.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Loss: 0.06460328869172123\n",
      "Accuracy on training set:\n",
      "Got 59110 / 60000 correct (98.52%)\n",
      "Accuracy on test set:\n",
      "Got 9901 / 10000 correct (99.01%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 103.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Loss: 0.05756620101621752\n",
      "Accuracy on training set:\n",
      "Got 59208 / 60000 correct (98.68%)\n",
      "Accuracy on test set:\n",
      "Got 9908 / 10000 correct (99.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 96.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Loss: 0.056097011828769264\n",
      "Accuracy on training set:\n",
      "Got 59216 / 60000 correct (98.69%)\n",
      "Accuracy on test set:\n",
      "Got 9909 / 10000 correct (99.09%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 107.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Loss: 0.051602877049482486\n",
      "Accuracy on training set:\n",
      "Got 59258 / 60000 correct (98.76%)\n",
      "Accuracy on test set:\n",
      "Got 9920 / 10000 correct (99.20%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        # Get data to cuda/mps if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Flatten image\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        scores = model(data)\n",
    "        loss = loss_function(scores, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "706ae4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            probs = softmax(scores)\n",
    "            predictions = torch.argmax(probs, dim=1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} correct ({float(num_correct)/float(num_samples)*100:.2f}%)\")\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "341591d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "Got 59295 / 60000 correct (98.83%)\n",
      "Accuracy on test set:\n",
      "Got 9920 / 10000 correct (99.20%)\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "print(\"Accuracy on training set:\")\n",
    "check_accuracy(train_loader, model)\n",
    "print(\"Accuracy on test set:\")\n",
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
